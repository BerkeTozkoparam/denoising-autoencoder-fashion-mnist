# -*- coding: utf-8 -*-
"""Autoencoders

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WVlE3tmenmvxnUdi1v_M60-vInPTN6J7
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE

from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam
from skimage.metrics import structural_similarity as ssim

# 1. Loading Dataset
# We use the Fashion MNIST dataset which contains 28x28 grayscale images of clothing items.
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# 2. Dataset Normalization
# Scaling pixel values to the range [0, 1] for better model convergence.
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# Flatten the data (converting 28x28 images into 784-dimensional vectors)
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))

# --- NEW ADDITION: NOISE INJECTION (DENOISING TASK) ---
# We add Gaussian noise to the images to challenge the model.
# The goal is to train the model to remove this noise (Denoising Autoencoder).
noise_factor = 0.2
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)

# Ensure pixel values remain within the valid [0, 1] range after adding noise
x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

# 3. Defining Parameters
input_dim = x_train.shape[1]  # 784
encoding_dim = 64             # Target dimension size

# 4. Building the Encoder
# Reduces the input dimensions from 784 down to 16 (in the bottleneck)
input_image = Input(shape=(input_dim,))
encoder = Dense(encoding_dim, activation='relu')(input_image)
encoder = Dense(int(encoding_dim/2), activation='relu')(encoder)
encoder_output = Dense(int(encoding_dim/4), activation='relu')(encoder) # Latent Space (Bottleneck: 16 dims)

# 5. Building the Decoder
# Reconstructs the original 784 dimensions from the bottleneck
decoded = Dense(int(encoding_dim/4), activation='relu')(encoder_output)
decoded = Dense(int(encoding_dim/2), activation='relu')(decoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded)

# 6. Creating the Autoencoder Model
autoencoder = Model(inputs=input_image, outputs=decoded)

# 7. Compiling the Model
autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')

# 8. Training the Model
# NOTICE: Input is 'noisy data', Target is 'clean original data' (x_train)
print("Training Model...")
history = autoencoder.fit(x_train_noisy, x_train,
                          epochs=20,
                          batch_size=128,
                          shuffle=True,
                          validation_data=(x_test_noisy, x_test))

# --- VISUALIZATION 1: TRAINING LOSS ---
# Plotting the loss to show convergence over epochs
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Development')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# 9. Separating Encoder for Analysis
encoder_model = Model(input_image, encoder_output)

# Generating predictions
encoded_images = encoder_model.predict(x_test)       # Get latent representations
decoded_images = autoencoder.predict(x_test_noisy)   # Get restored (denoised) images

# --- VISUALIZATION 2: RECONSTRUCTION RESULTS ---
# Comparing Original vs. Noisy Input vs. Restored Output
n = 10  # Number of digits to display
plt.figure(figsize=(20, 6))
for i in range(n):
    # Display Original
    ax = plt.subplot(3, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title("Original")
    plt.axis('off')

    # Display Noisy Input
    ax = plt.subplot(3, n, i + 1 + n)
    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')
    plt.title("Noisy Input")
    plt.axis('off')

    # Display Restored (Denoised) Result
    ax = plt.subplot(3, n, i + 1 + 2*n)
    plt.imshow(decoded_images[i].reshape(28, 28), cmap='gray')
    plt.title("Restored")
    plt.axis('off')
plt.show()

# --- VISUALIZATION 3: LATENT SPACE (t-SNE) ---
# Visualizing how the model clusters different clothing items in the 16D latent space
print("Visualizing Latent Space with t-SNE... This may take a moment.")
tsne = TSNE(n_components=2, random_state=42)
# Using a subset of 1000 images for speed
X_embedded = tsne.fit_transform(encoded_images[:1000])
y_subset = y_test[:1000]

plt.figure(figsize=(10, 8))
# Create a scatter plot where colors represent the actual classes (T-shirt, Trouser, etc.)
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_subset, cmap='jet', alpha=0.6)
plt.colorbar(scatter, label='Fashion MNIST Classes')
plt.title('Latent Space Clustering (t-SNE)')
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.grid(True)
plt.show()

# 10. Performance Metric: SSIM (Structural Similarity Index)
def compute_ssim(original, reconstructed):
    original = original.reshape(28, 28)
    reconstructed = reconstructed.reshape(28, 28)
    # data_range=1 because images are normalized between 0 and 1
    return ssim(original, reconstructed, data_range=1)

test_scores = []
for i in range(100):
    score = compute_ssim(x_test[i], decoded_images[i])
    test_scores.append(score)

print(f"Average SSIM on Restored Images (First 100 samples): {np.mean(test_scores):.4f}")